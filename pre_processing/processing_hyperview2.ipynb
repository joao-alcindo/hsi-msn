{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0640deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.decomposition import IncrementalPCA, PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "import multiprocessing  # <--- Importado para paralelismo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281ed866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "in_directory = \"./../hsi_airborne/\"\n",
    "out_directory = \"./../hsi_airborne/pca/\"\n",
    "npy_files = glob.glob(f\"{in_directory}*.npy\")\n",
    "\n",
    "n_files = len(npy_files)\n",
    "\n",
    "\n",
    "# create out directory if dont exist\n",
    "if not os.path.exists(out_directory):\n",
    "    os.makedirs(out_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe81b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parâmetros do Group-wise PCA\n",
    "TOTAL_NC = 32          # Número total de componentes principais desejado no final\n",
    "NUM_GROUPS = 4           # Em quantos grupos as bandas espectrais serão divididas\n",
    "\n",
    "# Dimensões esperadas de cada patch (bandas, altura, largura)\n",
    "DIMS = (430, 20, 20)\n",
    "\n",
    "\n",
    "# --- Verificações Iniciais ---\n",
    "if TOTAL_NC % NUM_GROUPS != 0:\n",
    "    raise ValueError(\"O número total de componentes (TOTAL_NC) deve ser divisível pelo número de grupos (NUM_GROUPS).\")\n",
    "NC_PER_GROUP = TOTAL_NC // NUM_GROUPS\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad89118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para processar um único arquivo .npy\n",
    "def process_single_file(data):\n",
    "    try:\n",
    "        X = data\n",
    "        # replace nan with 0\n",
    "        X = np.nan_to_num(X, nan=0.0)\n",
    "        if X.shape == DIMS:\n",
    "            X = np.moveaxis(X, 0, -1)\n",
    "\n",
    "            h, w, c = X.shape\n",
    "            \n",
    "            X = np.reshape(X, (-1, DIMS[0]))\n",
    "            return X, h, w, c\n",
    "    except Exception:\n",
    "        # Ignora arquivos corrompidos ou com erro de leitura\n",
    "        return None\n",
    "\n",
    "\n",
    "def split_data(data_list, group=4):\n",
    "    output_data = data_list\n",
    "    step = group // 2\n",
    "    for i in range(step):\n",
    "        split_data = []\n",
    "        for data in output_data:\n",
    "            n, c = data.shape\n",
    "            data_s1 = data[:, :c // 2]\n",
    "            data_s2 = data[:, c // 2:]\n",
    "            split_data.append(data_s1)\n",
    "            split_data.append(data_s2)\n",
    "        output_data = split_data\n",
    "    return output_data\n",
    "\n",
    "\n",
    "def applyGWPCA(X, nc=32, group=4, whiten=True):\n",
    "    h, w, c = X.shape\n",
    "    X = np.reshape(X, (-1, c))\n",
    "    X = (X - X.min()) / (np.max(X) - np.min(X))\n",
    "\n",
    "    X_split = split_data([X], group)\n",
    "    pca_data_list = []\n",
    "    for i, x in enumerate(X_split):\n",
    "        pca = PCA(n_components=nc // group, whiten=whiten, random_state=42)\n",
    "        pca_data = pca.fit_transform(x)\n",
    "        pca_data_list.append(pca_data)\n",
    "\n",
    "    out = np.concatenate(pca_data_list, axis=-1)\n",
    "    out = np.reshape(out, (h, w, -1))\n",
    "    return out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f57eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1876, 430, 20, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load(npy_files[0])\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e842513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Incremental PCA: 100%|██████████| 1876/1876 [00:37<00:00, 49.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# incremental pca\n",
    "\n",
    "# create the four ipca\n",
    "standardscaler = [StandardScaler() for _ in range(NUM_GROUPS)]\n",
    "ipcas = [IncrementalPCA(n_components=NC_PER_GROUP, whiten=True) for _ in range(NUM_GROUPS)]\n",
    "\n",
    "\n",
    "for i in tqdm(range(data.shape[0]), desc=\"Fitting Incremental PCA\"):\n",
    "    pixel_matrix = process_single_file(data[i])\n",
    "    if pixel_matrix is not None:\n",
    "        # Dividir os dados em grupos\n",
    "        grouped_data = split_data([pixel_matrix], group=NUM_GROUPS)\n",
    "        for i, group_data in enumerate(grouped_data):\n",
    "            # Ajustar o IPCA incrementalmente\n",
    "            ipcas[i].partial_fit(group_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e70e5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transforming and saving files: 100%|██████████| 1876/1876 [00:01<00:00, 1098.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# apply the pca tranform in all data\n",
    "\n",
    "name_file = 0\n",
    "\n",
    "for i in tqdm(range(data.shape[0]), desc=\"Transforming and saving files\"):\n",
    "    name_file += 1\n",
    "    pixel_matrix, h, w, c = process_single_file(data[i])\n",
    "    \n",
    "    if pixel_matrix is not None:\n",
    "        # Dividir os dados em grupos\n",
    "        grouped_data = split_data([pixel_matrix], group=NUM_GROUPS)\n",
    "        pca_data_list = []\n",
    "        for i, group_data in enumerate(grouped_data):\n",
    "            # Transformar os dados usando o IPCA ajustado\n",
    "            pca_data = ipcas[i].transform(group_data)\n",
    "            pca_data_list.append(pca_data)\n",
    "\n",
    "        # Concatenar os dados PCA de todos os grupos\n",
    "        out = np.concatenate(pca_data_list, axis=-1)\n",
    "        out = np.reshape(out, (h, w, -1))\n",
    "        # Salvar o resultado em um arquivo .npy\n",
    "        output_file = os.path.join(out_directory, f\"pca_{name_file:05d}_DATA.npy\")\n",
    "        np.save(output_file, out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsi-msn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
